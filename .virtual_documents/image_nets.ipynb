from pathlib import Path
from typing import Union, Callable, Any, Optional
import re
import os

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import torch
import torchvision

import util
import learning
import data_loaders

from importlib import reload

%load_ext lab_black


reload(learning)
reload(util)





breed_re = re.compile(r"(\D*)_\d*")


def extract_breed(file_name: str) -> str:
    return breed_re.match(file_name).group(1)


data_base_path = Path(r"F:/Coding/data-science/datasets/oxford-iiit-pet/images")
label_names = sorted(set([extract_breed(item) for item in os.listdir(data_base_path)]))
label_dict = {item: index for index, item in enumerate(label_names)}
print(label_dict)


# https://pytorch.org/vision/stable/auto_examples/plot_scripted_tensor_transforms.html#sphx-glr-auto-examples-plot-scripted-tensor-transforms-py
# transforms =torch.nn.Sequential(
#     torchvision.transforms.Resize(size=(224, 224)),
#     torchvision.transforms.RandomHorizontalFlip(p=0.3),
# )
transforms = torch.nn.Sequential(
    torchvision.transforms.Resize(size=(224, 224)),
    torchvision.transforms.TrivialAugmentWide(),
    # torchvision.transforms.Resize(size=(460, 460)),
    # torchvision.transforms.RandomHorizontalFlip(p=0.3),
    # torchvision.transforms.RandomRotation(30),
    # torchvision.transforms.CenterCrop(224)
)
valid_transforms = torch.nn.Sequential(torchvision.transforms.Resize(size=(224, 224)))


class OxfordPetImageDataset(torch.utils.data.TensorDataset):
    """
    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files
    """

    image_paths: list[str]

    def __init__(
        self,
        img_dir: Path,
        transform: Union[Callable[[torch.Tensor], torch.Tensor], None] = None,
        target_transform: Union[
            Callable[[Union[torch.Tensor, Any]], torch.Tensor], None
        ] = None,
        limit_data: Optional[int] = None,
    ):
        self.img_dir = img_dir
        self.image_paths = os.listdir(img_dir)
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx: int):
        file_name = self.image_paths[idx]
        label = extract_breed(file_name)

        img_path = self.img_dir / file_name
        try:
            # image = torchvision.io.read_image(str(img_path), torchvision.io.ImageReadMode.RGB).float() / 255
            # RandAugment requires unit8, don't perform float transform until after transofrm
            image = torchvision.io.read_image(
                str(img_path), torchvision.io.ImageReadMode.RGB
            )
        except:
            print(file_name, label, img_path)
        if self.transform:
            image = self.transform(image).float() / 255
        if self.target_transform:
            label = self.target_transform(label)
        return image, label


dataset = OxfordPetImageDataset(
    img_dir=data_base_path,
    # transform=torchvision.transforms.Resize(size=(224, 224)),
    transform=transforms,
    target_transform=torchvision.transforms.Lambda(
        lambda y: data_loaders.label_name_one_hot(y, label_dict)
    ),
    # limit_data=1000
)
train_dataset, valid_dataset = data_loaders.split_datasets(
    dataset, validation_percent=0.1, validation_transforms=valid_transforms
)
# test_dataset = OxfordPetImageDataset(
#     img_dir=data_base_path,
#     transform=torchvision.transforms.Resize(size=(224, 224))
# )


data_loaders.preview_data_sample(train_dataset, label_dict)


# Unsupported images despite jpg? There were only 6, removed them
# for img in dataset.image_paths:
#     try:
#         torchvision.io.read_image(str(data_base_path/img), torchvision.io.ImageReadMode.RGB).float() / 255
#     except:
#         print(img)


reload(learning)


model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT)
# Freeze all pretrained parameters to avoid using them in training
# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor
for param in model.parameters():
    param.requires_grad = False

# Replace the head (the last layer, aka the final classification layer) with our own randomized weights
# and output the appropriate number of classes for our problem.
# The last layer was trained for the particular classification problem that the original model was intended for
# It is never any good for you (unless you are doing an identical problem)
# Match the in features with those of the original last layer, then specify new ones for the out for your problem
# Note that different models may have different names for the classification layer (see "image_nets fine-tuning conversation.md")
model.fc = torch.nn.Linear(model.fc.in_features, len(label_dict.items())).to("cuda")

# optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)
optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)

learner = learning.Learner(
    data_loaders=learning.DataLoaders(
        # 32
        torch.utils.data.DataLoader(train_dataset, batch_size=64),
        torch.utils.data.DataLoader(valid_dataset, batch_size=64),
        # TODO: figure out test dataset (no labels? Just pass none for label or don't pass at all?)
        torch.utils.data.DataLoader(valid_dataset, batch_size=64),
    ),
    model=model,
    loss_function=torch.nn.CrossEntropyLoss(),
    metric_function=learning.accuracy,
    optimizer=optimizer,
    scheduler=None,
    device="cuda",
    # device="cpu"
    early_stop_patience=3,
    early_stop_min_delta=0.1,
)

# TODOs
# Best way to normalize image sizes
# See how much unfreezing prior layers helps (aka fine tuning?)


learner.learning_rate_find()


1e-2, 1e-3


torch.cuda.empty_cache()
learner.optimizer = torch.optim.Adam(model.fc.parameters(), lr=3e-3)
# Best accuracy so far: 89.2%, 3 epochs without unfreezing.
# TODO: Try unfreezing and training more
learner.train_model(epochs=20)


learner.plot_epoch_data()


data_loaders.preview_tested_data_sample(valid_dataset, model, label_dict, "cuda")





data_base_path = Path(r"F:\Coding\data-science\datasets\dog-breeds")
data_labels_df = pd.read_csv(data_base_path/"labels.csv")
label_names = sorted(data_labels_df['breed'].unique())
label_dict = {item: index for index, item in enumerate(label_names)}
for key in list(label_dict.keys())[:5]: print(f"{key}: {label_dict[key]}")


# https://pytorch.org/vision/stable/auto_examples/plot_scripted_tensor_transforms.html#sphx-glr-auto-examples-plot-scripted-tensor-transforms-py
transforms =torch.nn.Sequential(
    torchvision.transforms.Resize(size=(224, 224)),
    torchvision.transforms.RandomHorizontalFlip(p=0.3),
)
# transforms =torch.nn.Sequential(
#     torchvision.transforms.Resize(size=(360, 360)),
#     torchvision.transforms.RandomHorizontalFlip(p=0.3),
#     torchvision.transforms.RandomRotation(25),
#     torchvision.transforms.RandomCrop(224)
# )

class DogVisionImageDataset(torch.utils.data.TensorDataset):
    """
    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files
    """

    labels_df: pd.DataFrame

    def __init__(
        self,
        img_dir: Path,
        labels_df: pd.DataFrame = None,
        transform: Union[Callable[[torch.Tensor], torch.Tensor], None] = None,
        target_transform: Union[Callable[[Union[torch.Tensor, Any]], torch.Tensor], None] = None,
        limit_data: Optional[int] = None,
    ):
        self.labels_df = labels_df
        
        if limit_data:
            self.labels_df = self.labels_df[:limit_data]
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx: int):
        file_name = self.labels_df.iloc[idx, 0]
        label = self.labels_df.iloc[idx, 1]
        
        img_path = self.img_dir/f"{str(file_name)}.jpg"
        image = torchvision.io.read_image(str(img_path), torchvision.io.ImageReadMode.RGB).float() / 255
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        return image, label

dataset = DogVisionImageDataset(
    img_dir=data_base_path/"train",
    labels_df=data_labels_df,
    # transform=torchvision.transforms.Resize(size=(224, 224)),
    transform=transforms,
    target_transform=torchvision.transforms.Lambda(lambda y: data_loaders.label_name_one_hot(y, label_dict)),
    # limit_data=1000
)
train_dataset, valid_dataset = data_loaders.split_datasets(dataset, validation_percent=0.1)
test_dataset = DogVisionImageDataset(
    img_dir=data_base_path/"test",
    transform=torchvision.transforms.Resize(size=(224, 224))
)



len(dataset)


data_loaders.preview_data_sample(train_dataset, label_dict)


torch.cuda.empty_cache()
model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT)
# Freeze all pretrained parameters to avoid using them in training
# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor
for param in model.parameters():
    param.requires_grad = False

# Replace the head (the last layer, aka the final classification layer) with our own randomized weights
# and output the appropriate number of classes for our problem.
# The last layer was trained for the particular classification problem that the original model was intended for
# It is never any good for you (unless you are doing an identical problem)
# Match the in features with those of the original last layer, then specify new ones for the out for your problem
# Note that different models may have different names for the classification layer (see "image_nets fine-tuning conversation.md")
model.fc = torch.nn.Linear(model.fc.in_features, len(label_dict.items())).to("cuda")

epochs = 20
# optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)
optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)

learner = learning.Learner(
    data_loaders=learning.DataLoaders(
        # 32
        torch.utils.data.DataLoader(train_dataset, batch_size=128), 
        torch.utils.data.DataLoader(valid_dataset, batch_size=128),
        # TODO: figure out test dataset (no labels? Just pass none for label or don't pass at all?)
        torch.utils.data.DataLoader(valid_dataset, batch_size=128)
    ),
    model=model,
    loss_function=torch.nn.CrossEntropyLoss(),
    metric_function=learning.accuracy,
    optimizer=optimizer,
    scheduler=None,
    device="cuda"
    # device="cpu"
)

# TODOs
# Best way to normalize image sizes
# See how much unfreezing prior layers helps (aka fine tuning?)
learner.train_model(epochs=epochs)


learner.plot_epoch_data()


reload(data_loaders)


data_loaders.preview_tested_data_sample(valid_dataset, model, label_dict, "cuda")


# TODO: add early stopping algo
# TODO: look up better pytorch notebooks for this dataset
# TODO: implement fit_one_cycle algo
