from pathlib import Path
from typing import Union, Callable, Any, Optional
import re
import os

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import torch
import torchvision

import util
import learning
import data_helpers

from importlib import reload

%load_ext lab_black


reload(learning)
reload(data_helpers)





breed_re = re.compile(r"(\D*)_\d*")


def extract_breed(file_name: str) -> str:
    return breed_re.match(file_name).group(1)


data_base_path = Path(r"F:/Coding/data-science/datasets/oxford-iiit-pet/images")
label_names = sorted(set([extract_breed(item) for item in os.listdir(data_base_path)]))
label_dict = {item: index for index, item in enumerate(label_names)}
print(label_dict)


# https://pytorch.org/vision/stable/auto_examples/plot_scripted_tensor_transforms.html#sphx-glr-auto-examples-plot-scripted-tensor-transforms-py
transforms = torch.nn.Sequential(
    torchvision.transforms.Resize(size=(224, 224)),
    torchvision.transforms.RandomHorizontalFlip(p=0.3),
)
# transforms = torch.nn.Sequential(
#     torchvision.transforms.Resize(size=(224, 224)),
#     torchvision.transforms.TrivialAugmentWide(),
#     # torchvision.transforms.Resize(size=(460, 460)),
#     # torchvision.transforms.RandomHorizontalFlip(p=0.3),
#     # torchvision.transforms.RandomRotation(30),
#     # torchvision.transforms.CenterCrop(224)
# )
valid_transforms = torch.nn.Sequential(torchvision.transforms.Resize(size=(224, 224)))


class OxfordPetImageDataset(torch.utils.data.TensorDataset):
    """
    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files
    """

    image_paths: list[str]

    def __init__(
        self,
        img_dir: Path,
        transform: Union[Callable[[torch.Tensor], torch.Tensor], None] = None,
        target_transform: Union[
            Callable[[Union[torch.Tensor, Any]], torch.Tensor], None
        ] = None,
        limit_data: Optional[int] = None,
    ):
        self.img_dir = img_dir
        self.image_paths = os.listdir(img_dir)
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx: int):
        file_name = self.image_paths[idx]
        label = extract_breed(file_name)

        img_path = self.img_dir / file_name
        try:
            # image = torchvision.io.read_image(str(img_path), torchvision.io.ImageReadMode.RGB).float() / 255
            # RandAugment requires unit8, don't perform float transform until after transofrm
            image = torchvision.io.read_image(
                str(img_path), torchvision.io.ImageReadMode.RGB
            )
        except:
            print(file_name, label, img_path)
        if self.transform:
            image = self.transform(image).float() / 255
        if self.target_transform:
            label = self.target_transform(label)
        return image, label


dataset = OxfordPetImageDataset(
    img_dir=data_base_path,
    # transform=torchvision.transforms.Resize(size=(224, 224)),
    transform=transforms,
    target_transform=torchvision.transforms.Lambda(
        lambda y: data_loaders.label_name_one_hot(y, label_dict)
    ),
    # limit_data=1000
)
train_dataset, valid_dataset = data_loaders.split_datasets(
    dataset, validation_percent=0.1, validation_transforms=valid_transforms
)
# test_dataset = OxfordPetImageDataset(
#     img_dir=data_base_path,
#     transform=torchvision.transforms.Resize(size=(224, 224))
# )


data_loaders.preview_data_sample(train_dataset, label_dict)


# Unsupported images despite jpg? There were only 6, removed them
# for img in dataset.image_paths:
#     try:
#         torchvision.io.read_image(str(data_base_path/img), torchvision.io.ImageReadMode.RGB).float() / 255
#     except:
#         print(img)


reload(learning)


model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT)
# Freeze all pretrained parameters to avoid using them in training
# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor
for param in model.parameters():
    param.requires_grad = False

# Replace the head (the last layer, aka the final classification layer) with our own randomized weights
# and output the appropriate number of classes for our problem.
# The last layer was trained for the particular classification problem that the original model was intended for
# It is never any good for you (unless you are doing an identical problem)
# Match the in features with those of the original last layer, then specify new ones for the out for your problem
# Note that different models may have different names for the classification layer (see "image_nets fine-tuning conversation.md")
model.fc = torch.nn.Linear(model.fc.in_features, len(label_dict.items())).to("cuda")

# optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)
optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)

learner = learning.Learner(
    data_loaders=learning.DataLoaders(
        # 32 is most common batch size? Most recommended? Fastai used 64
        torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True),
        torch.utils.data.DataLoader(valid_dataset, batch_size=64),
    ),
    model=model,
    loss_function=torch.nn.CrossEntropyLoss(),
    metric_function=learning.accuracy,
    optimizer=optimizer,
    scheduler=None,
    device="cuda",
    # device="cpu"
    early_stop_patience=3,
    early_stop_min_delta=0.1,
    restore_min_loss_state=True,
)

# TODOs
# Best way to normalize image sizes
# See how much unfreezing prior layers helps (aka fine tuning?)


learner.learning_rate_find()


1e-2, 1e-3


torch.cuda.empty_cache()
learner.optimizer = torch.optim.Adam(model.fc.parameters(), lr=3e-3)
# Best accuracy so far: 89.2%, 3 epochs without unfreezing, no data augments.
# TODO: Try unfreezing and training more
# TODO: Try a more complex final layer, with convnet then fc?
learner.train_model(epochs=3)


learner.save_model(Path("test_model.pt"))


learner.load_model(Path("test_model.pt"))


learner.plot_epoch_data()


data_loaders.preview_tested_data_sample(
    valid_dataset, learner.model, label_dict, "cuda"
)


from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay


preds, labels = learner.get_preds(learner.data_loaders.valid)


cm = confusion_matrix(labels.argmax(dim=1).tolist(), preds.argmax(dim=1).tolist())
cm


max_by_row = []
for row_num, row in enumerate(cm):
    row_no_identity = row.copy()
    row_no_identity[row_num] = -1
    max = row_no_identity.max()
    max_idx = row_no_identity.tolist().index(max)
    max_by_row.append((row_num, max_idx, max))

max_by_row = sorted(max_by_row, key=lambda x: x[2], reverse=True)
max_by_row


reload(data_helpers)


data_helpers.most_confused(preds, labels, label_names, 2)


data_helpers.plot_confusion_matrix(preds, labels, label_names)





data_base_path = Path(r"F:\Coding\data-science\datasets\dog-breeds")
data_labels_df = pd.read_csv(data_base_path/"labels.csv")
label_names = sorted(data_labels_df['breed'].unique())
label_dict = {item: index for index, item in enumerate(label_names)}
for key in list(label_dict.keys())[:5]: print(f"{key}: {label_dict[key]}")


# https://pytorch.org/vision/stable/auto_examples/plot_scripted_tensor_transforms.html#sphx-glr-auto-examples-plot-scripted-tensor-transforms-py
transforms =torch.nn.Sequential(
    torchvision.transforms.Resize(size=(224, 224)),
    torchvision.transforms.RandomHorizontalFlip(p=0.3),
)
# transforms =torch.nn.Sequential(
#     torchvision.transforms.Resize(size=(360, 360)),
#     torchvision.transforms.RandomHorizontalFlip(p=0.3),
#     torchvision.transforms.RandomRotation(25),
#     torchvision.transforms.RandomCrop(224)
# )

class DogVisionImageDataset(torch.utils.data.TensorDataset):
    """
    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files
    """

    labels_df: pd.DataFrame

    def __init__(
        self,
        img_dir: Path,
        labels_df: pd.DataFrame = None,
        transform: Union[Callable[[torch.Tensor], torch.Tensor], None] = None,
        target_transform: Union[Callable[[Union[torch.Tensor, Any]], torch.Tensor], None] = None,
        limit_data: Optional[int] = None,
    ):
        self.labels_df = labels_df
        
        if limit_data:
            self.labels_df = self.labels_df[:limit_data]
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx: int):
        file_name = self.labels_df.iloc[idx, 0]
        label = self.labels_df.iloc[idx, 1]
        
        img_path = self.img_dir/f"{str(file_name)}.jpg"
        image = torchvision.io.read_image(str(img_path), torchvision.io.ImageReadMode.RGB).float() / 255
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        return image, label

dataset = DogVisionImageDataset(
    img_dir=data_base_path/"train",
    labels_df=data_labels_df,
    # transform=torchvision.transforms.Resize(size=(224, 224)),
    transform=transforms,
    target_transform=torchvision.transforms.Lambda(lambda y: data_loaders.label_name_one_hot(y, label_dict)),
    # limit_data=1000
)
train_dataset, valid_dataset = data_loaders.split_datasets(dataset, validation_percent=0.1)
test_dataset = DogVisionImageDataset(
    img_dir=data_base_path/"test",
    transform=torchvision.transforms.Resize(size=(224, 224))
)



len(dataset)


data_loaders.preview_data_sample(train_dataset, label_dict)


torch.cuda.empty_cache()
model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT)
# Freeze all pretrained parameters to avoid using them in training
# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor
for param in model.parameters():
    param.requires_grad = False

# Replace the head (the last layer, aka the final classification layer) with our own randomized weights
# and output the appropriate number of classes for our problem.
# The last layer was trained for the particular classification problem that the original model was intended for
# It is never any good for you (unless you are doing an identical problem)
# Match the in features with those of the original last layer, then specify new ones for the out for your problem
# Note that different models may have different names for the classification layer (see "image_nets fine-tuning conversation.md")
model.fc = torch.nn.Linear(model.fc.in_features, len(label_dict.items())).to("cuda")

epochs = 20
# optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)
optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)

learner = learning.Learner(
    data_loaders=learning.DataLoaders(
        # 32
        torch.utils.data.DataLoader(train_dataset, batch_size=128), 
        torch.utils.data.DataLoader(valid_dataset, batch_size=128),
        # TODO: figure out test dataset (no labels? Just pass none for label or don't pass at all?)
        torch.utils.data.DataLoader(valid_dataset, batch_size=128)
    ),
    model=model,
    loss_function=torch.nn.CrossEntropyLoss(),
    metric_function=learning.accuracy,
    optimizer=optimizer,
    scheduler=None,
    device="cuda"
    # device="cpu"
)

# TODOs
# Best way to normalize image sizes
# See how much unfreezing prior layers helps (aka fine tuning?)
learner.train_model(epochs=epochs)


learner.plot_epoch_data()


reload(data_loaders)


data_loaders.preview_tested_data_sample(valid_dataset, model, label_dict, "cuda")


# TODO: add early stopping algo
# TODO: look up better pytorch notebooks for this dataset
# TODO: implement fit_one_cycle algo
